{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0e406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halvornedrebo/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/halvornedrebo/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "2025-05-06 15:00:59.807902: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from preprocessing.advanced import clean_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59cb8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e3a0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/cengelsen/Dokumenter/studier/info381/kode/info381/data/fraud.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/tc77nkws71lbvgc7p8nh7jz40000gn/T/ipykernel_10379/1031409558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fraud.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Programmering/INFO381/preprocessing/advanced.py\u001b[0m in \u001b[0;36mclean_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Importing data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDensityAwareClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/cengelsen/Dokumenter/studier/info381/kode/info381/data/fraud.csv'"
     ]
    }
   ],
   "source": [
    "data = clean_data(\"fraud.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d30cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"is_fraud\", axis=1)\n",
    "y = data[\"is_fraud\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1a3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a39239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE Sampling with Grid Search\n",
    "\n",
    "## Define the pipeline\n",
    "\n",
    "smote = SMOTE(\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc75a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82443777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "model_xgb = xgb.XGBClassifier(tree_method=\"hist\", enable_categorical=True, device=\"cuda\")\n",
    "model_xgb.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f472ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification report\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Fraud\", \"Fraud\"])\n",
    "disp.plot(cmap=\"Oranges\")\n",
    "plt.savefig(\"confusion_matrix_xgboost_advanced.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9026de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shapley values\n",
    "explainer = shap.TreeExplainer(model_xgb)\n",
    "explanation = explainer(X_test)\n",
    "\n",
    "shap_values = explanation.values\n",
    "np.abs(shap_values.sum(axis=1) + explanation.base_values - y_pred).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f8107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_plot = shap.Explanation(\n",
    "    values=shap_values,\n",
    "    base_values=explanation.base_values,\n",
    "    data=X_test,\n",
    "    feature_names=X.columns.tolist()\n",
    ")\n",
    "\n",
    "shap.plots.beeswarm(explanation_plot, max_display=10)\n",
    "plt.savefig(\"shap_beeswarm_xgboost_advanced.png\")\n",
    "plt.close()\n",
    "\n",
    "shap.plots.bar(explanation_plot, max_display=10)\n",
    "plt.savefig(\"shap_bar_xgboost_advanced.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a20849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import AnchorTabular\n",
    "feature_names = X.columns.tolist()\n",
    "predict_fn = lambda x: model_xgb.predict_proba(x)\n",
    "\n",
    "explainer = AnchorTabular(predict_fn, feature_names)\n",
    "\n",
    "explainer.fit(X_train_smote, disc_perc=(5, 10, 15, 25, 50, 75, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df091e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds global rules\n",
    "\n",
    "anchors = []\n",
    "for i in tqdm(range(len(X_test[:100]))):  # or len(X_test)\n",
    "    instance = X_test[i]\n",
    "    explanation = explainer.explain(\n",
    "        instance, \n",
    "        threshold=0.95, \n",
    "        verbose=False,\n",
    "        batch_size=1024,\n",
    "        )\n",
    "    anchors.append(tuple(explanation.anchor))  # store as tuple for counting\n",
    "\n",
    "anchor_counts = Counter(anchors)\n",
    "print(\"Most common anchor rules for XGBoost:\")\n",
    "for rule, count in anchor_counts.most_common(10):\n",
    "    print(f\"{rule}: {count} times\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "nn = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "nn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', \n",
    "             tf.keras.metrics.Precision(name='precision'), \n",
    "             tf.keras.metrics.Recall(name='recall'),\n",
    "             tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "history = nn.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc99f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification report\n",
    "y_pred_prob = nn.predict(X_test).flatten()\n",
    "threshold = 0.2  # Try different values\n",
    "y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"Not Fraud\", \"Fraud\"]).plot(cmap=\"Blues\")\n",
    "disp.plot()\n",
    "plt.savefig(\"confusion_matrix_nn.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44666518",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_test))\n",
    "\n",
    "background = X_train[np.random.choice(X_train.shape[0], 1000, replace=False)]\n",
    "\n",
    "print(f\"Using {len(background)} samples for SHAP analysis\")\n",
    "\n",
    "# Initialize SHAP explainer with TensorFlow model\n",
    "print(\"Initializing SHAP DeepExplainer...\")\n",
    "explainer = shap.DeepExplainer(nn, background)\n",
    "\n",
    "# Calculate SHAP values\n",
    "print(\"Calculating SHAP values...\")\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "\n",
    "print(f\"SHAP values type: {type(shap_values)}\")\n",
    "print(f\"Length of SHAP list: {len(shap_values)}\")\n",
    "print(f\"Shape of first element: {np.array(shap_values[0]).shape}\")\n",
    "print(f\"Shape of second element: {np.array(shap_values[1]).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the actual structure of the returned SHAP values\n",
    "if isinstance(shap_values, list):\n",
    "    # If DeepExplainer returned a list of arrays (one per class)\n",
    "    shap_values_class_0 = shap_values[0]\n",
    "    shap_values_class_1 = shap_values[1]\n",
    "else:\n",
    "    # If DeepExplainer returned a single array\n",
    "    # For binary classification with a sigmoid output, the SHAP values\n",
    "    # represent the positive class (fraud)\n",
    "    shap_values_class_1 = shap_values\n",
    "    # For the negative class, we can take the negative of the SHAP values\n",
    "    shap_values_class_0 = -shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12635276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure proper shape: should match X_test's shape\n",
    "if shap_values_class_0.shape != X_test.shape:\n",
    "    shap_values_class_0 = np.squeeze(shap_values_class_0)\n",
    "if shap_values_class_1.shape != X_test.shape:\n",
    "    shap_values_class_1 = np.squeeze(shap_values_class_1)\n",
    "\n",
    "feature_names = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5219e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary plots\n",
    "print(\"\\nGenerating summary plot for non-fraud (class 0)...\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values_class_0, X_test, feature_names=feature_names, \n",
    "                 max_display=10, show=False, plot_type=\"bar\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_nonfraud.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nGenerating summary plot for fraud (class 1)...\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values_class_1, X_test, feature_names=feature_names, \n",
    "                 max_display=10, show=False, plot_type=\"bar\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_fraud.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac20ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating beeswarm plot for non-fraud (class 0)...\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "explanation_nonfraud = shap.Explanation(\n",
    "    values=shap_values_class_0,\n",
    "    base_values=np.repeat(explainer.expected_value[0] if isinstance(explainer.expected_value, list) \n",
    "                          else explainer.expected_value, X_test.shape[0]),\n",
    "    data=X_test,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "shap.plots.beeswarm(explanation_nonfraud, max_display=10, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_beeswarm_nonfraud.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753de59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating beeswarm plot for fraud (class 1)...\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "explanation_fraud = shap.Explanation(\n",
    "    values=shap_values_class_1,\n",
    "    base_values=np.repeat(explainer.expected_value[1] if isinstance(explainer.expected_value, list) \n",
    "                         else explainer.expected_value, X_test.shape[0]),\n",
    "    data=X_test,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "shap.plots.beeswarm(explanation_fraud, max_display=10, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_beeswarm_fraud.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91baaca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All SHAP plots saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(x):\n",
    "    # Returns predicted class labels\n",
    "    return (nn.predict(x, verbose=0) >= 0.5).astype(int).flatten()\n",
    "\n",
    "\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = AnchorTabular(predict_fn, feature_names)\n",
    "explainer.fit(X_train)\n",
    "\n",
    "X_test_sample = shuffle(X_test, random_state=42)\n",
    "\n",
    "anchors = []\n",
    "for i in tqdm(range(len(X_test_sample[:100]))):  # or len(X_test)\n",
    "    instance = X_test_sample[i]\n",
    "    explanation = explainer.explain(\n",
    "        instance, \n",
    "        threshold=0.95, \n",
    "        verbose=False,\n",
    "        batch_size=1024,\n",
    "        )\n",
    "    anchors.append(tuple(explanation.anchor))  # store as tuple for counting\n",
    "\n",
    "anchor_counts = Counter(anchors)\n",
    "print(\"Most common anchor rules for NN:\")\n",
    "for rule, count in anchor_counts.most_common(10):\n",
    "    print(f\"{rule}: {count} times\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
