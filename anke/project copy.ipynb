{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "\n",
    "training = \"/Users/ankelovset/Documents/Master/2. Semester/INFO381 - Artificial Intelligence/Project381/archive (1)/fraudTrain.csv\"\n",
    "testing = \"/Users/ankelovset/Documents/Master/2. Semester/INFO381 - Artificial Intelligence/Project381/archive (1)/fraudTest.csv\"\n",
    "\n",
    "df_train = pd.read_csv(training)\n",
    "df_test = pd.read_csv(testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting relevant features\n",
    "features = [\"trans_date_trans_time\", \"category\", \"amt\", \"gender\", \"zip\", \"city_pop\", \"job\", \"dob\", \"merch_lat\", \"merch_long\", \"is_fraud\"]\n",
    "df_train = df_train[features]\n",
    "df_test = df_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "df_train[\"trans_date_trans_time\"] = pd.to_datetime(df_train[\"trans_date_trans_time\"])\n",
    "df_train[\"dob\"] = pd.to_datetime(df_train[\"dob\"])\n",
    "df_test[\"trans_date_trans_time\"] = pd.to_datetime(df_test[\"trans_date_trans_time\"])\n",
    "df_test[\"dob\"] = pd.to_datetime(df_test[\"dob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create age feature\n",
    "df_train[\"age\"] = (df_train[\"trans_date_trans_time\"] - df_train[\"dob\"]).dt.days // 365\n",
    "df_test[\"age\"] = (df_test[\"trans_date_trans_time\"] - df_test[\"dob\"]).dt.days // 365\n",
    "df_train.drop(columns=[\"dob\", \"trans_date_trans_time\"], inplace=True)\n",
    "df_test.drop(columns=[\"dob\", \"trans_date_trans_time\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "categorical_cols = [\"category\", \"gender\", \"job\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col])\n",
    "    \n",
    "    # Map test data with known categories, set unknown labels to -1\n",
    "    df_test[col] = df_test[col].map(lambda s: le.transform([s])[0] if s in le.classes_ else -1)\n",
    "\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df_train.fillna(df_train.median(), inplace=True)\n",
    "df_test.fillna(df_test.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features and target variable\n",
    "X_train = df_train.drop(columns=[\"is_fraud\"])\n",
    "y_train = df_train[\"is_fraud\"]\n",
    "X_test = df_test.drop(columns=[\"is_fraud\"])\n",
    "y_test = df_test[\"is_fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = [\"amt\", \"zip\", \"city_pop\", \"merch_lat\", \"merch_long\", \"age\"]\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=500, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing feature importance\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=np.abs(model.coef_).flatten(), y=X_train.columns)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance in Fraud Detection (Logistic Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrules import SkopeRules\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify categorical and numerical features\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess (encode) categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # keep numerical columns as-is\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fit the SkopeRules model\n",
    "skope = SkopeRules(\n",
    "    feature_names=preprocessor.get_feature_names_out(),\n",
    "    precision_min=0.5,\n",
    "    recall_min=0.01,\n",
    "    n_estimators=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "skope.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Predict and evaluate\n",
    "y_pred_skope = skope.predict(X_test_transformed)\n",
    "\n",
    "print(\"SkopeRules Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_skope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_skope)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Fraud\", \"Fraud\"])\n",
    "disp.plot(cmap=\"Oranges\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
